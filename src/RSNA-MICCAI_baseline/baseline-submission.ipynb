{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"!pip install pydicom -q","metadata":{"execution":{"iopub.status.busy":"2021-09-11T05:44:05.385098Z","iopub.execute_input":"2021-09-11T05:44:05.385447Z","iopub.status.idle":"2021-09-11T05:44:33.336886Z","shell.execute_reply.started":"2021-09-11T05:44:05.385361Z","shell.execute_reply":"2021-09-11T05:44:33.336066Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/d/kozodoi/timm-pytorch-image-models/pytorch-image-models-master/')","metadata":{"execution":{"iopub.status.busy":"2021-09-11T05:44:33.340674Z","iopub.execute_input":"2021-09-11T05:44:33.340927Z","iopub.status.idle":"2021-09-11T05:44:33.346923Z","shell.execute_reply.started":"2021-09-11T05:44:33.340898Z","shell.execute_reply":"2021-09-11T05:44:33.346184Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# General imports.\nimport random\nimport pydicom\nimport platform\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport albumentations as A\nimport sklearn\nimport cv2\nimport timm\nimport torch\nimport torch.nn as nn\n\n# Specific imports. \nfrom collections import Counter\nfrom multiprocessing import Pool\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nfrom tqdm.notebook import tqdm\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n\nimport warnings\nwarnings.simplefilter('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-09-11T05:44:33.349750Z","iopub.execute_input":"2021-09-11T05:44:33.349980Z","iopub.status.idle":"2021-09-11T05:44:40.950841Z","shell.execute_reply.started":"2021-09-11T05:44:33.349946Z","shell.execute_reply":"2021-09-11T05:44:40.949960Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Utility Functions","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed=123):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T05:44:40.955891Z","iopub.execute_input":"2021-09-11T05:44:40.956179Z","iopub.status.idle":"2021-09-11T05:44:40.962869Z","shell.execute_reply.started":"2021-09-11T05:44:40.956143Z","shell.execute_reply":"2021-09-11T05:44:40.962201Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Converting to PNGs and Extracting Meta DataFrame","metadata":{}},{"cell_type":"code","source":"# For fast submissions.\nsample_submission = pd.read_csv(r\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv\")\nfast_sub = True if sample_submission.shape[0] == 87 else False\nfast_cnt = 3","metadata":{"execution":{"iopub.status.busy":"2021-09-11T05:44:40.964421Z","iopub.execute_input":"2021-09-11T05:44:40.964647Z","iopub.status.idle":"2021-09-11T05:44:40.983810Z","shell.execute_reply.started":"2021-09-11T05:44:40.964619Z","shell.execute_reply":"2021-09-11T05:44:40.983200Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Data is here: https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification/data.\n\nmode = \"test\"\nmeta_df_name = \"test_meta\"\npng_image_path_root = \"./images/\"\ncomp_data_root = \"../input/rsna-miccai-brain-tumor-radiogenomic-classification/\"\nmeta_df_root = \"./\"\n\nos.makedirs(png_image_path_root, exist_ok=True)\nos.makedirs(meta_df_root, exist_ok=True)\n\nclass ME:\n    def __init__(self, file_path, ImageID, PatientID, mpMRI_type):\n        self.file_path = file_path\n        self.ImageID = ImageID\n        self.PatientID = PatientID\n        self.mpMRI_type = mpMRI_type\n\n        \ndef dicom2image(ele):\n    dcm_file = pydicom.read_file(ele.file_path)\n    \n    PatientID = dcm_file.PatientID\n    StudyInstanceUID = dcm_file.StudyInstanceUID\n    SeriesInstanceUID = dcm_file.SeriesInstanceUID\n    SeriesDescription = dcm_file.SeriesDescription  # This is the mpMRI scan type.\n\n    assert PatientID == ele.PatientID, \"DCM Image patientid and file path patientid do not match!\"\n    assert SeriesDescription == ele.mpMRI_type, \"SeriesDescription and mpMRI scan type do not match!\"\n\n    data = apply_voi_lut(dcm_file.pixel_array, dcm_file)\n\n    if dcm_file.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n\n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n\n    image_path = os.path.join(png_image_path_root, f\"{PatientID}_{SeriesDescription}_{ele.ImageID}.png\")\n    cv2.imwrite(image_path, data)\n    \n    return [ele.file_path, image_path, PatientID, SeriesDescription, ele.ImageID, StudyInstanceUID, SeriesInstanceUID]\n\n# cnt is for counting and for fast submission.\nc = Counter()\nimages_meta = []\nfor root, dirs, files in os.walk(os.path.join(comp_data_root, f\"{mode}/\")):\n    if len(files) != 0 and (\".dcm\" in files[0] or \".dicom\" in files[0]):\n        split = root.split(\"/\")\n        patientid = split[-2]\n        mpMRI_type = split[-1]\n\n        c[patientid] += 1\n        for file in files:\n            full_path = os.path.join(root, file)\n            ImageID = file.split(\".\")[0]  # Get the image file name.\n            \n            dcm_file = pydicom.read_file(full_path)\n            PatientID = dcm_file.PatientID\n            SeriesDescription = dcm_file.SeriesDescription  # This is the mpMRI scan type.\n            \n            images_meta.append(ME(full_path, ImageID, PatientID, SeriesDescription))\n        \n        # For fast submissions.\n        if fast_sub and len(dict(c).keys()) == fast_cnt:\n            break\n        \np = Pool(16)\nresults = p.map(func=dicom2image, iterable=images_meta)\nmeta_df = pd.DataFrame(\n        data=np.array(results), \n        columns=[\"dicom_filepath\", \"png_filepath\", \"PatientID\", \"SeriesDescription\", \"ImageID\", \"StudyInstanceUID\", \"SeriesInstanceUID\"])\n\n# This part is for when the PatientIDs are turned into ints (for some weird reason).\npatientids = [x.split(\"/\")[-3] for x in meta_df.dicom_filepath.values]\nmeta_df.PatientID = patientids\n\nmeta_df.to_csv(os.path.join(meta_df_root, f\"{meta_df_name}.csv\"), index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T05:44:40.986315Z","iopub.execute_input":"2021-09-11T05:44:40.986497Z","iopub.status.idle":"2021-09-11T05:44:53.669014Z","shell.execute_reply.started":"2021-09-11T05:44:40.986476Z","shell.execute_reply":"2021-09-11T05:44:53.667784Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Building the Dataset","metadata":{}},{"cell_type":"code","source":"test_meta = pd.read_csv(\"test_meta.csv\")\ntest_meta.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T05:44:53.671348Z","iopub.execute_input":"2021-09-11T05:44:53.671671Z","iopub.status.idle":"2021-09-11T05:44:53.708880Z","shell.execute_reply.started":"2021-09-11T05:44:53.671618Z","shell.execute_reply":"2021-09-11T05:44:53.708188Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                      dicom_filepath  \\\n0  ../input/rsna-miccai-brain-tumor-radiogenomic-...   \n1  ../input/rsna-miccai-brain-tumor-radiogenomic-...   \n2  ../input/rsna-miccai-brain-tumor-radiogenomic-...   \n3  ../input/rsna-miccai-brain-tumor-radiogenomic-...   \n4  ../input/rsna-miccai-brain-tumor-radiogenomic-...   \n\n                      png_filepath  PatientID SeriesDescription   ImageID  \\\n0   ./images/00114_T2w_Image-4.png        114               T2w   Image-4   \n1   ./images/00114_T2w_Image-2.png        114               T2w   Image-2   \n2   ./images/00114_T2w_Image-3.png        114               T2w   Image-3   \n3   ./images/00114_T2w_Image-5.png        114               T2w   Image-5   \n4  ./images/00114_T2w_Image-19.png        114               T2w  Image-19   \n\n                                    StudyInstanceUID  \\\n0  1.2.826.0.1.3680043.8.498.38439529458846212961...   \n1  1.2.826.0.1.3680043.8.498.38439529458846212961...   \n2  1.2.826.0.1.3680043.8.498.38439529458846212961...   \n3  1.2.826.0.1.3680043.8.498.38439529458846212961...   \n4  1.2.826.0.1.3680043.8.498.38439529458846212961...   \n\n                                   SeriesInstanceUID  \n0  1.2.826.0.1.3680043.8.498.91885894975366405300...  \n1  1.2.826.0.1.3680043.8.498.91885894975366405300...  \n2  1.2.826.0.1.3680043.8.498.91885894975366405300...  \n3  1.2.826.0.1.3680043.8.498.91885894975366405300...  \n4  1.2.826.0.1.3680043.8.498.91885894975366405300...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dicom_filepath</th>\n      <th>png_filepath</th>\n      <th>PatientID</th>\n      <th>SeriesDescription</th>\n      <th>ImageID</th>\n      <th>StudyInstanceUID</th>\n      <th>SeriesInstanceUID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../input/rsna-miccai-brain-tumor-radiogenomic-...</td>\n      <td>./images/00114_T2w_Image-4.png</td>\n      <td>114</td>\n      <td>T2w</td>\n      <td>Image-4</td>\n      <td>1.2.826.0.1.3680043.8.498.38439529458846212961...</td>\n      <td>1.2.826.0.1.3680043.8.498.91885894975366405300...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../input/rsna-miccai-brain-tumor-radiogenomic-...</td>\n      <td>./images/00114_T2w_Image-2.png</td>\n      <td>114</td>\n      <td>T2w</td>\n      <td>Image-2</td>\n      <td>1.2.826.0.1.3680043.8.498.38439529458846212961...</td>\n      <td>1.2.826.0.1.3680043.8.498.91885894975366405300...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../input/rsna-miccai-brain-tumor-radiogenomic-...</td>\n      <td>./images/00114_T2w_Image-3.png</td>\n      <td>114</td>\n      <td>T2w</td>\n      <td>Image-3</td>\n      <td>1.2.826.0.1.3680043.8.498.38439529458846212961...</td>\n      <td>1.2.826.0.1.3680043.8.498.91885894975366405300...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../input/rsna-miccai-brain-tumor-radiogenomic-...</td>\n      <td>./images/00114_T2w_Image-5.png</td>\n      <td>114</td>\n      <td>T2w</td>\n      <td>Image-5</td>\n      <td>1.2.826.0.1.3680043.8.498.38439529458846212961...</td>\n      <td>1.2.826.0.1.3680043.8.498.91885894975366405300...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../input/rsna-miccai-brain-tumor-radiogenomic-...</td>\n      <td>./images/00114_T2w_Image-19.png</td>\n      <td>114</td>\n      <td>T2w</td>\n      <td>Image-19</td>\n      <td>1.2.826.0.1.3680043.8.498.38439529458846212961...</td>\n      <td>1.2.826.0.1.3680043.8.498.91885894975366405300...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class RsnaMiccaiDataset(Dataset):\n    def __init__(self, df, images_dir, image_size, mode, classes, by_patient=False):\n        super(RsnaMiccaiDataset, self).__init__()\n        self.df = df.reset_index(drop=True)\n        self.images_dir = images_dir\n        self.image_size = image_size\n        assert mode in ['train', 'valid', 'test']\n        self.mode = mode\n        self.classes = classes\n\n        self.patient_ids = self.df.PatientID.sort_values().reset_index(drop=True).unique()\n        self.by_patient = by_patient\n\n        if self.mode == 'train':\n            self.df = self.df.sample(frac=1).reset_index(drop=True)\n\n            self.transform = A.Compose([\n                # A.RandomResizedCrop(height=self.image_size, width=self.image_size, scale=(0.25, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1, p=1.0),\n                # A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=30, interpolation=1, border_mode=0, value=0, p=0.25),\n                # A.HorizontalFlip(p=0.5),\n                # A.VerticalFlip(p=0.5),\n                # A.OneOf([\n                #     A.MotionBlur(p=.2),\n                #     A.MedianBlur(blur_limit=3, p=0.1),\n                #     A.Blur(blur_limit=3, p=0.1),\n                # ], p=0.25),\n                # A.OneOf([\n                #     A.CLAHE(clip_limit=2),\n                #     A.IAASharpen(),\n                #     A.IAAEmboss(),\n                #     A.RandomBrightnessContrast(),            \n                # ], p=0.25),\n                # A.Cutout(num_holes=8, max_h_size=32, max_w_size=32, fill_value=0, p=0.25),\n\n                A.Resize(self.image_size, self.image_size),\n                A.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD),\n                ToTensorV2(),\n            ])\n        else:\n            self.transform = A.Compose([\n                A.Resize(self.image_size, self.image_size),\n                A.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD),\n                ToTensorV2(),\n            ])\n\n    def __len__(self):\n        if self.by_patient: return len(self.patient_ids)\n        return len(self.df)\n\n    def __getitem__(self, index):\n        if self.mode == \"test\":\n            patientid = self.patient_ids[index]\n            df_sliced_by_patientid = self.df[self.df.PatientID == patientid].reset_index(drop=True)\n            images = []\n            for idx, row in df_sliced_by_patientid.iterrows():\n                if idx % 5 == 0:\n                    image = cv2.imread(row.png_filepath, cv2.IMREAD_GRAYSCALE)\n                    image = np.stack([image, image, image],axis=-1)\n                    image = self.transform(image=image)['image']\n                    images.append(image)\n            image = torch.mean(torch.stack(images), dim=0)\n            return patientid, image\n        else:\n            if self.by_patient:\n                patientid = self.patient_ids[index]\n                df_sliced_by_patientid = self.df[self.df.PatientID == patientid].reset_index(drop=True)\n                images = []\n                for idx, row in df_sliced_by_patientid.iterrows():\n                    if idx % 5 == 0:\n                        image = cv2.imread(row.png_filepath, cv2.IMREAD_GRAYSCALE)\n                        image = np.stack([image, image, image],axis=-1)\n                        image = self.transform(image=image)['image']\n                        images.append(image)\n                image = torch.mean(torch.stack(images), dim=0)\n                assert df_sliced_by_patientid.MGMT_value.nunique() == 1, f\"The mpMRI scan conclusions for patient {patientid} disagree with each other!\"\n                label = torch.FloatTensor(df_sliced_by_patientid.loc[0, self.classes])\n                return image, label\n\n\n            img_path = '{}/{}'.format(self.images_dir, self.df.loc[index, 'png_filepath'])\n            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n            image = np.stack([image, image, image], axis=-1)\n            image = self.transform(image=image)['image']\n            label = torch.FloatTensor(self.df.loc[index, self.classes])\n            return image, label","metadata":{"execution":{"iopub.status.busy":"2021-09-11T05:44:53.710162Z","iopub.execute_input":"2021-09-11T05:44:53.710398Z","iopub.status.idle":"2021-09-11T05:44:53.730478Z","shell.execute_reply.started":"2021-09-11T05:44:53.710367Z","shell.execute_reply":"2021-09-11T05:44:53.729824Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameters","metadata":{}},{"cell_type":"code","source":"class Config:\n    model_name = \"tf_efficientnet_b0\"\n    batch_size = 32\n    image_size = 512\n    num_workers = 0\n    epochs = 30\n    init_lr = 0.001\n    fold_type = \"fold_gkf_patientid\"\n\n    # Final params.\n    folds = 5\n    classes = [\"MGMT_value\"]\n    n_classes = len(classes)\n    project_name = \"RSNA-MICCAI_baseline\"\n    ckpt_dir = \".\"\n    seed_everything()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T05:44:53.731937Z","iopub.execute_input":"2021-09-11T05:44:53.732381Z","iopub.status.idle":"2021-09-11T05:44:53.751793Z","shell.execute_reply.started":"2021-09-11T05:44:53.732346Z","shell.execute_reply":"2021-09-11T05:44:53.751025Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Building the Model","metadata":{}},{"cell_type":"code","source":"cfg = Config()\n\nmodel = timm.create_model(cfg.model_name, pretrained=False)\nmodel = nn.Sequential(*list(model.children()),\n                        nn.Linear(1000, cfg.n_classes))\nmodel.load_state_dict(torch.load(r\"../input/baseline-models/fold0_epoch3.pt\"))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T05:44:53.755259Z","iopub.execute_input":"2021-09-11T05:44:53.755512Z","iopub.status.idle":"2021-09-11T05:45:00.037185Z","shell.execute_reply.started":"2021-09-11T05:44:53.755480Z","shell.execute_reply":"2021-09-11T05:45:00.036292Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"infer_ds = RsnaMiccaiDataset(\n    test_meta, \".\", \n    image_size=cfg.image_size, \n    mode=\"test\",\n    classes=cfg.classes, \n    by_patient=True\n)\n\ninfer_loader = DataLoader(\n    infer_ds, \n    batch_size=cfg.batch_size,\n    sampler=RandomSampler(infer_ds), \n    num_workers=cfg.num_workers,\n    drop_last=False\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T05:45:00.041355Z","iopub.execute_input":"2021-09-11T05:45:00.043724Z","iopub.status.idle":"2021-09-11T05:45:00.055500Z","shell.execute_reply.started":"2021-09-11T05:45:00.043682Z","shell.execute_reply":"2021-09-11T05:45:00.054673Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel.eval().to(device)\npredictions = []\npatientids = []\nfor patient_ids, images in tqdm(infer_loader):\n    images = images.to(device).float()\n\n    with torch.cuda.amp.autocast(), torch.no_grad():\n        outputs = model(images)\n        predictions.append(outputs.data.cpu().numpy())\n        patientids.append(patient_ids.data.cpu().numpy())","metadata":{"execution":{"iopub.status.busy":"2021-09-11T05:45:00.056917Z","iopub.execute_input":"2021-09-11T05:45:00.057252Z","iopub.status.idle":"2021-09-11T05:45:02.279792Z","shell.execute_reply.started":"2021-09-11T05:45:00.057216Z","shell.execute_reply":"2021-09-11T05:45:02.277240Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe554beb64234e27bd25abd26e02a0b4"}},"metadata":{}}]},{"cell_type":"code","source":"ids = [str(x).zfill(5) for x in np.concatenate(patientids)]\npreds = np.concatenate(predictions).flatten()\nsubmission = pd.DataFrame({\"BraTS21ID\": ids, \"MGMT_value\": preds})\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T05:45:02.281886Z","iopub.execute_input":"2021-09-11T05:45:02.282343Z","iopub.status.idle":"2021-09-11T05:45:02.294281Z","shell.execute_reply.started":"2021-09-11T05:45:02.282304Z","shell.execute_reply":"2021-09-11T05:45:02.293353Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2021-09-11T05:45:02.296227Z","iopub.execute_input":"2021-09-11T05:45:02.297236Z","iopub.status.idle":"2021-09-11T05:45:02.310227Z","shell.execute_reply.started":"2021-09-11T05:45:02.297202Z","shell.execute_reply":"2021-09-11T05:45:02.309562Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"  BraTS21ID  MGMT_value\n0     00114    0.339111\n1     00013    0.277832\n2     00821    0.249146","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BraTS21ID</th>\n      <th>MGMT_value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00114</td>\n      <td>0.339111</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00013</td>\n      <td>0.277832</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00821</td>\n      <td>0.249146</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!rm test_meta.csv\n!rm -rf images/","metadata":{"execution":{"iopub.status.busy":"2021-09-11T05:45:02.311396Z","iopub.execute_input":"2021-09-11T05:45:02.311706Z","iopub.status.idle":"2021-09-11T05:45:03.797384Z","shell.execute_reply.started":"2021-09-11T05:45:02.311673Z","shell.execute_reply":"2021-09-11T05:45:03.796196Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}